{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62b8f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Optimized Sigma: 0.1\n",
      "Validation RMSE: 12.520172463776085\n",
      "Test RMSE: 11.82798423043457\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "Number of neurons (training examples) used: 2959\n",
      "                                              Product  Forecasted Quantity\n",
      "19          Cetirizine (Saphzine) 10mg Tab 100&#039;s           276.079595\n",
      "13         Cetirizine (Cetrinova) 10mg Tab 100&#039;s           264.063354\n",
      "12  Cetirizine (Ceticit/ Cetirigen) 10mg Tab 100&#...           249.674947\n",
      "26  Chlorphenamine Maleate (Riphen/ Allermax) 4mg ...           112.704116\n",
      "32  Diphenhydramine HCL (Mucomed) 25mg Cap 100&#039;s            96.217746\n",
      "36  Levocetirizine Dihydrochloride (Allecure) 5mg ...            72.484450\n",
      "43  Loratadine (Lorarex/ Lorasaph) 10mg Tab 100&#0...            66.713741\n",
      "42                  Loratadine (Claritin) 10mg Tablet            52.888015\n",
      "28  Diphenhydramine HCL (BENADRYL AH) 25mg Cap 100...            47.295545\n",
      "46                                  Nasatapp 15mg Tab            46.263878\n",
      "38  Levocetirizine Dihydrochloride (Locetin) 5mg 1...            44.763567\n",
      "29  Diphenhydramine HCL (BENADRYL AH) 50mg Cap 100...            43.745969\n",
      "33   Ebastine Betamethasone ( Co Aleva ) 10/0.5mg Tab            41.137062\n",
      "23  Cetirizine + PPE (ALNIX PLUS) 10mg Tab 100&#039;s            38.890135\n",
      "41         Loratadine (Allerta) 10mg Tablet 50&#039;s            36.481886\n",
      "8              Cetirizine (ALNIX) 10mg Tab 100&#039;s            35.386562\n",
      "37  Levocetirizine Dihydrochloride (Levizine) 5mg ...            32.467664\n",
      "44  Loratadine + Betamethasone (CLARICORT) 5/250mc...            31.427515\n",
      "6                               Alnix Plus Syrup 60ml            30.998458\n",
      "45  Montelukast + Levocetirizine (Montephil/Montez...            26.208722\n",
      "31  Diphenhydramine HCL (Histazyn) 50mg Cap 100&#0...            24.028621\n",
      "11       Cetirizine (CETI-MED) 10mg Tablet 100&#039;s            23.140829\n",
      "21            Cetirizine (ZYRTEC) 10mg Tab 100&#039;s            23.137233\n",
      "7                    Bilastine 20mg (BILAXTEN) Tablet            23.099206\n",
      "20                    Cetirizine (VIRLIX) 10mg Tablet            18.677732\n",
      "39  Levocetirizine Dihydrochloride (XYZAL) 5mg 100...            18.356642\n",
      "18                 Cetirizine (Saphzine 5) Syrup 60ml            15.180420\n",
      "34         Levocetirizine (ALLERZET) 2.5/5ml Syr 30ml            13.249632\n",
      "9   Cetirizine (Allecur/ Dialix/ Rhinisaph 5/ Alle...            13.033843\n",
      "14   Cetirizine (Cetrisaph 5/ Medrizine) 5mg/5ml 60ml            11.936656\n",
      "15              Cetirizine (Myrex) 10mg/ml Drops 10ml            10.790782\n",
      "17                     Cetirizine (Reax) 5mg/5ml 60ml            10.073924\n",
      "16                    Cetirizine (Myrex) 5mg/5ml 60ml             9.955288\n",
      "22                   Cetirizine (Zyrine) 5mg/5ml 60ml             9.904228\n",
      "1                                       Allerkid 60ml             9.682443\n",
      "0                                       Allerkid 30ml             9.510242\n",
      "5                              Alnix Drops 2.5mg 10ml             8.376754\n",
      "10  Cetirizine (Allecur/Cetrisaph OD/ Medrizine/Ce...             8.018766\n",
      "40                                   Loraped Syr 60ml             8.001682\n",
      "4                              Alnix 5mg/5ml Syr 60ml             8.000079\n",
      "27     Diphenhydramine (Diahist) 12.5mg/5ml Susp 60ml             8.000062\n",
      "2                        Allerkid Drops 2.5mg/ml 10ml             8.000018\n",
      "24  Cetirizine(Allecur P/ Cetalert) 2.5mg/ml Drops...             8.000003\n",
      "35         Levocetirizine (ALLERZET) 2.5/5ml Syr 60ml             8.000000\n",
      "3                              Alnix 5mg/5ml Syr 30ml             8.000000\n",
      "25          Chlorphenamine (Riphen) 2mg/5ml Susp 60ml             8.000000\n",
      "30  Diphenhydramine HCL (BENADRYL AH) Syrup 12.5/5...             8.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import Layer, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('antihistamine.csv')\n",
    "\n",
    "# Convert 'Sold_date' to datetime format and set as index\n",
    "df['Sold_date'] = pd.to_datetime(df['Sold_date'], format='%m/%d/%y')\n",
    "df.set_index('Sold_date', inplace=True)\n",
    "\n",
    "# Instead of aggregating, directly proceed with the existing dataframe\n",
    "df_encoded = pd.concat([df, pd.get_dummies(df['Product_details'], prefix='product')], axis=1).drop('Product_details', axis=1)\n",
    "\n",
    "# Extract year and week number from 'Sold_date' for temporal features\n",
    "df_encoded['year'] = df_encoded.index.year\n",
    "df_encoded['week_of_year'] = df_encoded.index.isocalendar().week\n",
    "\n",
    "# Normalize the temporal features \n",
    "scaler = MinMaxScaler()\n",
    "features_columns = ['year', 'week_of_year'] + [col for col in df_encoded.columns if col.startswith('product')]\n",
    "df_encoded[features_columns] = scaler.fit_transform(df_encoded[features_columns])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_encoded[features_columns].values\n",
    "y = df_encoded['Sold_quantity'].values  # Assuming 'Sold_quantity' is the target variable\n",
    "\n",
    "# The rest of the code remains the same for splitting the data, defining the GRNN prediction function, etc.\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the dataset into training, validation, and testing sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42)  # 0.1765 of 85% is roughly 15% of the whole\n",
    "\n",
    "# Define the Gaussian kernel function\n",
    "def gaussian_kernel(distance, sigma=0.5):\n",
    "    return np.exp(-distance**2 / (2 * sigma**2))\n",
    "\n",
    "# GRNN prediction function\n",
    "def grnn_predict(X_train, y_train, X_test, sigma=0.5):\n",
    "    \n",
    "    # Display the number of neurons (training examples) being used\n",
    "    print(f'Number of neurons (training examples) used: {X_train.shape[0]}')\n",
    "    \n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    for i, x_test in enumerate(X_test):\n",
    "        distances = np.linalg.norm(X_train - x_test, axis=1)\n",
    "        weights = gaussian_kernel(distances, sigma)\n",
    "        numerator = np.sum(weights * y_train)\n",
    "        denominator = np.sum(weights)\n",
    "        predictions[i] = numerator / denominator if denominator > 0 else 0\n",
    "    return predictions\n",
    "\n",
    "# Optimizing sigma using the validation set\n",
    "sigma_values = np.linspace(0.1, 2.0, 20)\n",
    "sigma_performance = []\n",
    "for sigma in sigma_values:\n",
    "    val_predictions = grnn_predict(X_train, y_train, X_val, sigma)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "    sigma_performance.append((sigma, val_rmse))\n",
    "best_sigma, best_val_rmse = min(sigma_performance, key=lambda x: x[1])\n",
    "\n",
    "# Using the best sigma to make predictions on the test set\n",
    "predictions = grnn_predict(X_train, y_train, X_test, best_sigma)\n",
    "\n",
    "# Evaluate the model\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Optimized Sigma: {best_sigma}')\n",
    "print(f'Validation RMSE: {best_val_rmse}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "\n",
    "# Prepare for forecasting\n",
    "def prepare_forecast_features(date_range, features_columns, scaler):\n",
    "    forecast_features = []\n",
    "    for date in date_range:\n",
    "        feature_vector = np.zeros((1, len(features_columns)))\n",
    "        year_index = features_columns.index('year')\n",
    "        week_of_year_index = features_columns.index('week_of_year')\n",
    "        \n",
    "        # Normalize year and week_of_year for the forecast date\n",
    "        feature_vector[0, year_index] = (date.year - scaler.data_min_[year_index]) / (scaler.data_max_[year_index] - scaler.data_min_[year_index])\n",
    "        feature_vector[0, week_of_year_index] = (date.isocalendar().week - scaler.data_min_[week_of_year_index]) / (scaler.data_max_[week_of_year_index]\n",
    "        - scaler.data_min_[week_of_year_index])\n",
    "        \n",
    "        forecast_features.append(feature_vector)\n",
    "        \n",
    "    return np.vstack(forecast_features)\n",
    "\n",
    "# Define the forecast period\n",
    "forecast_start = datetime(2024, 2, 1)\n",
    "forecast_end = datetime(2024, 2, 8)\n",
    "forecast_dates = pd.date_range(forecast_start, forecast_end).to_pydatetime().tolist()\n",
    "\n",
    "# Prepare forecast features\n",
    "forecast_features = prepare_forecast_features(forecast_dates, features_columns, scaler)\n",
    "\n",
    "# Making predictions for the forecast period\n",
    "forecast_predictions = {}\n",
    "for col in features_columns:\n",
    "    if col.startswith('product_'):\n",
    "        product_forecast_features = np.copy(forecast_features)\n",
    "        product_index = features_columns.index(col)\n",
    "        \n",
    "        # Activate current product feature\n",
    "        product_forecast_features[:, product_index] = 1  # Set the product to active\n",
    "        \n",
    "        # Predict with GRNN for the forecast period using the best sigma\n",
    "        product_predictions = grnn_predict(X_train, y_train, product_forecast_features, best_sigma)\n",
    "        \n",
    "        # Aggregate predictions for the product over the forecast period\n",
    "        forecast_predictions[col.replace('product_', '')] = np.sum(product_predictions)\n",
    "\n",
    "# Display forecasted quantities for each product\n",
    "forecast_df = pd.DataFrame(list(forecast_predictions.items()), columns=['Product', 'Forecasted Quantity']).sort_values(by='Forecasted Quantity', ascending=False)\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c502267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
